# ğŸ¯ AI-Driven Automated Interviewer for Project Presentations

A complete AI system that conducts adaptive interviews by analyzing student project presentations through screen sharing and speech recognition.

## ğŸŒŸ Features

- **Real-time Screen Analysis**: OCR extraction from slides, code, and diagrams
- **Speech-to-Text**: Live transcription of student presentations
- **Adaptive Interviewing**: Context-aware questions based on content
- **Smart Evaluation**: Scores on technical depth, clarity, originality, and understanding
- **Live Dashboard**: Real-time presentation monitoring and Q&A

## ğŸ—ï¸ Architecture

```
Frontend (React + WebRTC)
    â†“
Backend API (FastAPI)
    â†“
Processing Pipeline:
    â†’ Screen Capture + OCR (Tesseract)
    â†’ Audio â†’ STT (Whisper)
    â†’ Content Analysis (Claude API)
    â†’ Question Generation
    â†’ Response Evaluation
```

## ğŸ“‹ Prerequisites

- Python 3.9+
- Node.js 16+
- Anthropic API Key (for Claude)
- FFmpeg (for audio processing)

## ğŸš€ Quick Start

### 1. Backend Setup

```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

Create `.env` file:
```env
ANTHROPIC_API_KEY=your_api_key_here
PORT=8000
```

Run backend:
```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### 2. Frontend Setup

```bash
cd frontend
npm install
```

Create `.env` file:
```env
REACT_APP_API_URL=http://localhost:8000
```

Run frontend:
```bash
npm start
```

Visit: http://localhost:3000

## ğŸ“ Project Structure

```
ai-interviewer-system/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ ocr_service.py      # Screen OCR processing
â”‚   â”‚   â”œâ”€â”€ stt_service.py      # Speech-to-text
â”‚   â”‚   â”œâ”€â”€ ai_interviewer.py   # AI question generation
â”‚   â”‚   â””â”€â”€ evaluator.py        # Scoring engine
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py          # Data models
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ helpers.py          # Utility functions
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ScreenCapture.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioRecorder.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ InterviewPanel.jsx
â”‚   â”‚   â”‚   â””â”€â”€ EvaluationReport.jsx
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ index.jsx
â”‚   â””â”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸ® How to Use

1. **Start Presentation**: Click "Start Interview" and share your screen
2. **Present Your Project**: Speak naturally while showing slides/code
3. **Answer Questions**: AI will ask adaptive questions based on your content
4. **Get Feedback**: Receive detailed evaluation at the end

## ğŸ§ª Testing

### Test the Backend
```bash
cd backend
pytest tests/
```

### Test the Frontend
```bash
cd frontend
npm test
```

## ğŸ”§ Configuration

### AI Model Settings
Edit `backend/config.py`:
- `MODEL_NAME`: Claude model to use (default: claude-sonnet-4-5-20250929)
- `MAX_QUESTIONS`: Maximum questions per session
- `EVALUATION_CRITERIA`: Scoring weights

### OCR Settings
- `OCR_LANG`: Language for OCR (default: eng)
- `OCR_DPI`: Image DPI for processing

## ğŸ“Š Evaluation Metrics

The system scores presentations on:
- **Technical Depth (30%)**: Implementation complexity and understanding
- **Clarity (25%)**: Communication and explanation quality
- **Originality (25%)**: Innovation and unique approaches
- **Understanding (20%)**: Response quality and problem-solving

## ğŸŒ API Endpoints

- `POST /api/session/start` - Start interview session
- `POST /api/screen/analyze` - Analyze screen capture
- `POST /api/audio/transcribe` - Transcribe audio
- `POST /api/interview/question` - Get next question
- `POST /api/session/evaluate` - Get final evaluation
- `GET /api/session/{id}` - Get session details

## ğŸ› Troubleshooting

**Issue**: OCR not working
- Solution: Install Tesseract: `brew install tesseract` (Mac) or `apt-get install tesseract-ocr` (Linux)

**Issue**: Audio recording fails
- Solution: Grant microphone permissions in browser

**Issue**: WebSocket connection fails
- Solution: Check CORS settings in backend and firewall rules

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

## ğŸ“ License

MIT License - feel free to use for your hackathon and beyond!

## ğŸ‘¥ Team

Built for [Your Hackathon Name] - [Your Team Name]

## ğŸ™ Acknowledgments

- Anthropic Claude API for AI capabilities
- OpenAI Whisper for speech recognition
- Tesseract OCR for text extraction

---

**Good luck with your hackathon! ğŸš€**
